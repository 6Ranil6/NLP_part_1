{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "rwlxK5AYASaT"
      },
      "outputs": [],
      "source": [
        "# Данный ноутбук использовал окружение google-colab\n",
        "# %pip install catboost fasttext -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xRUXhCVUzur"
      },
      "source": [
        "# Домашнее задание \"NLP. Часть 1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "koQiHQFT8XO7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-04 15:41:17.345110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-04 15:41:17.832686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-04 15:41:19.225975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Dict, Tuple, Any\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZUhaEvmpTCsv"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_q88wy8uTDZh"
      },
      "outputs": [],
      "source": [
        "def normalize_pretokenize_text(text: str) -> List[str]:\n",
        "    text = text.lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uGDzAEpJT_zs"
      },
      "outputs": [],
      "source": [
        "# This block is for tests only\n",
        "test_corpus = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"never jump over the lazy dog quickly\",\n",
        "    \"brown foxes are quick and dogs are lazy\"\n",
        "]\n",
        "\n",
        "def build_vocab(texts: List[str]) -> Tuple[List[str], Dict[str, int]]:\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        words = normalize_pretokenize_text(text)\n",
        "        all_words.extend(words)\n",
        "    vocab = sorted(set(all_words))\n",
        "    vocab_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "    return vocab, vocab_index\n",
        "\n",
        "vocab, vocab_index = build_vocab(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eemkFZ1tVLw4"
      },
      "source": [
        "## Задание 1 (0.5 балла)\n",
        "Реализовать One-Hot векторизацию текстов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qiw7w5OhTDeD"
      },
      "outputs": [],
      "source": [
        "def one_hot_vectorization(text: str, vocab: List[str] = None, vocab_index: Dict[str, int] = None) -> List[int]:\n",
        "    vector_size = len(vocab)\n",
        "    res = []\n",
        "    words = normalize_pretokenize_text(text)\n",
        "    for word in words:\n",
        "        vec = [0] * vector_size\n",
        "        vec[vocab_index[word]] = 1\n",
        "        res.append(vec)\n",
        "    return res\n",
        "\n",
        "def test_one_hot_vectorization(corpus, vocab, vocab_index) -> bool:\n",
        "    try:\n",
        "        text = \"the quick brown fox\"\n",
        "        result = one_hot_vectorization(text, vocab, vocab_index)\n",
        "\n",
        "        if not isinstance(result, list):\n",
        "            return False\n",
        "\n",
        "        expected_length = len(vocab)\n",
        "        if len(result[0]) != expected_length:\n",
        "            return False\n",
        "\n",
        "        words_in_text = normalize_pretokenize_text(text)\n",
        "        for i, word in enumerate(words_in_text):\n",
        "            if word in vocab_index:\n",
        "                idx = vocab_index[word]\n",
        "                if result[i][idx] != 1:\n",
        "                    return False\n",
        "\n",
        "        print(\"One-Hot-Vectors test PASSED\")\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"One-Hot-Vectors test FAILED: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Q2-LJcmbTe04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Hot-Vectors test PASSED\n"
          ]
        }
      ],
      "source": [
        "assert test_one_hot_vectorization(test_corpus, vocab, vocab_index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAF8IOYMVT3s"
      },
      "source": [
        "## Задание 2 (0.5 балла)\n",
        "Реализовать Bag-of-Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-_QjiviNBkbS"
      },
      "outputs": [],
      "source": [
        "def bag_of_words_vectorization(text: str) -> Dict[str, int]:\n",
        "    return dict(Counter(normalize_pretokenize_text(text)))\n",
        "\n",
        "def test_bag_of_words_vectorization() -> bool:\n",
        "    try:\n",
        "        text = \"the the quick brown brown brown\"\n",
        "        result = bag_of_words_vectorization(text)\n",
        "\n",
        "        if not isinstance(result, dict):\n",
        "            return False\n",
        "\n",
        "        if result.get('the', 0) != 2:\n",
        "            return False\n",
        "        if result.get('quick', 0) != 1:\n",
        "            return False\n",
        "        if result.get('brown', 0) != 3:\n",
        "            return False\n",
        "        if result.get('nonexistent', 0) != 0:\n",
        "            return False\n",
        "\n",
        "        print(\"Bad-of-Words test PASSED\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Bag-of-Words test FAILED: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ScFuXh_9TtJm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bad-of-Words test PASSED\n"
          ]
        }
      ],
      "source": [
        "assert test_bag_of_words_vectorization()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6LblWJfX2kr"
      },
      "source": [
        "## Задание 3 (0.5 балла)\n",
        "Реализовать TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "def tf_transform(vector):\n",
        "    doc_terms_count = sum(vector)\n",
        "    print(doc_terms_count)\n",
        "    if sum(vector) == 0:\n",
        "        return vector\n",
        "    else:\n",
        "        return list(map(lambda k : round(k / doc_terms_count, 3), vector))\n",
        "\n",
        "def idf_transform(count_matrix):\n",
        "    D = len(count_matrix)\n",
        "\n",
        "    n = len(count_matrix[0])\n",
        "    \n",
        "    counter_list = [0] * n\n",
        "    for line in count_matrix:\n",
        "        for j in range(n):\n",
        "            if line[j] > 0:\n",
        "                counter_list[j] += 1\n",
        "\n",
        "    return [round(log((D + 1) / (el + 1)) + 1, 1) for el in counter_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RqcMYJkrTlV0"
      },
      "outputs": [],
      "source": [
        "from CountVectorizer import CountVectorizer\n",
        "from typing import List, Dict\n",
        "\n",
        "# Изначально была такая сигнатура, но из-за созданного класса Count Vectorizer не нужны параметры vocab и vocab_index: def tf_idf_vectorization(text: str, corpus: List[str] = None, vocab: List[str] = None, vocab_index: Dict[str, int] = None) -> List[float]:\n",
        "def tf_idf_vectorization(text: str, corpus: List[str] = None) -> List[float]:\n",
        "    vectorizer = CountVectorizer()\n",
        "    count_matrix = vectorizer.fit_transform(corpus)\n",
        "    res_idf = idf_transform(count_matrix)\n",
        "    \n",
        "    vector = vectorizer.transform(text)\n",
        "    res_tf = tf_transform(vector)\n",
        "    return (np.array(res_tf) * np.array(res_idf)).tolist()\n",
        "\n",
        "# Аналогично: def test_tf_idf_vectorization(corpus, vocab, vocab_index) -> bool:\n",
        "def test_tf_idf_vectorization(corpus) -> bool:\n",
        "    try:\n",
        "        text = \"the quick brown\"\n",
        "        result = tf_idf_vectorization(text, corpus)\n",
        "        if not isinstance(result, list):\n",
        "            return False\n",
        "\n",
        "        expected_length = len(vocab)\n",
        "        if len(result) != expected_length:\n",
        "            return False\n",
        "\n",
        "        for val in result:\n",
        "            if not isinstance(val, float):\n",
        "                return False\n",
        "\n",
        "        print(\"TF-IDF test PASSED\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"TF-IDF test FAILED: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GKIyS724T0XH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "TF-IDF test PASSED\n"
          ]
        }
      ],
      "source": [
        "assert test_tf_idf_vectorization(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Реализация всего TF-IDF можно найти в файле `tfidf.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0f9FZCrX5_s"
      },
      "source": [
        "## Задание 4 (1 балл)\n",
        "Реализовать Positive Pointwise Mutual Information (PPMI).  \n",
        "https://en.wikipedia.org/wiki/Pointwise_mutual_information\n",
        "$$PPMI(word, context) = max(0, PMI(word, context))$$\n",
        "$$PMI(word, context) = log \\frac{P(word, context)}{P(word) P(context)} = log \\frac{N(word, context)|(word, context)|}{N(word) N(context)}$$\n",
        "где $N(word, context)$ -- число вхождений слова $word$ в окно $context$ (размер окна -- гиперпараметр)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SUg6K2-wTwr6"
      },
      "outputs": [],
      "source": [
        "def ppmi_vectorization(\n",
        "    text: str,\n",
        "    corpus: List[str] = None,\n",
        "    vocab: List[str] = None,\n",
        "    vocab_index: Dict[str, int] = None,\n",
        "    window_size: int = 3\n",
        ") -> List[float]:\n",
        "\n",
        "    # Сначала обучение модели, где результат PPMI матрица\n",
        "    total_windows = 0 \n",
        "    matrix = np.zeros((len(vocab), len(vocab)))\n",
        "    for sent in corpus:\n",
        "        tokens = sent.lower().split()\n",
        "\n",
        "        for i, center_word in enumerate(tokens):\n",
        "            center_word_idx = vocab_index[center_word]\n",
        "            \n",
        "            start = max(0, i - window_size)\n",
        "            end = min(len(tokens), i + window_size + 1)\n",
        "            for j in range(start, end):\n",
        "                if i == j: \n",
        "                    continue\n",
        "                context_word = tokens[j]\n",
        "                context_word_idx = vocab_index[context_word]\n",
        "\n",
        "                matrix[center_word_idx, context_word_idx] += 1\n",
        "                total_windows += 1\n",
        "\n",
        "    N_center = matrix.sum(axis= 1)\n",
        "    N_context = matrix.sum(axis= 0)\n",
        "    ppmi_matrix = np.maximum(0, np.log((matrix * total_windows) / (N_center.reshape(-1, 1) * N_context.reshape(1, -1) + 1e-6)))\n",
        "\n",
        "    # Инференс - просто берем слова из ppmi и усредняем их\n",
        "    inf_tokens = text.lower().split()\n",
        "    vectors = []\n",
        "    for token in inf_tokens:\n",
        "        vectors.append(ppmi_matrix[vocab_index[token]])\n",
        "    \n",
        "    return np.mean(vectors, axis= 0).tolist()\n",
        "\n",
        "def test_ppmi_vectorization(corpus, vocab, vocab_index) -> bool:\n",
        "    try:\n",
        "        text = \"quick brown fox\"\n",
        "        result = ppmi_vectorization(text, corpus, vocab, vocab_index)\n",
        "\n",
        "        if not isinstance(result, list):\n",
        "            return False\n",
        "\n",
        "        expected_length = len(vocab)\n",
        "        if len(result) != expected_length:\n",
        "            return False\n",
        "\n",
        "        for val in result:\n",
        "            if not isinstance(val, float):\n",
        "                return False\n",
        "\n",
        "        print(\"PPMI test PASSED\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"PPMI test FAILED: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HgHmNZy75XFV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PPMI test PASSED\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13626/3989263913.py:31: RuntimeWarning: divide by zero encountered in log\n",
            "  ppmi_matrix = np.maximum(0, np.log((matrix * total_windows) / (N_center.reshape(-1, 1) * N_context.reshape(1, -1) + 1e-6)))\n"
          ]
        }
      ],
      "source": [
        "assert test_ppmi_vectorization(test_corpus, vocab, vocab_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK29va3PBH_8"
      },
      "source": [
        "## Задание 5 (1 балл)\n",
        "Реализовать получение эмбеддингов из fasttext и bert (для bert лучше использовать CLS токен)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tOe8dRLl5eqN"
      },
      "outputs": [],
      "source": [
        "def get_fasttext_embeddings(text: str, model_path: str = 'cc.ru.300.bin', model: any = None) -> List[np.ndarray]:\n",
        "    tokens = normalize_pretokenize_text(text)\n",
        "    if model is None:\n",
        "        if model_path:\n",
        "            model = fasttext.load_model(model_path)\n",
        "        else:\n",
        "            print(\"Нужно передать саму модель или путь к ней\")\n",
        "    model : fasttext.FastText\n",
        "    \n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        vectors.append(model.get_word_vector(token))\n",
        "\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([-0.02120868, -0.05426134, -0.03531325,  0.06754214,  0.0250404 ,\n",
              "         0.01246092, -0.01154722, -0.00579364, -0.02345451,  0.03992337,\n",
              "         0.12516876,  0.09337895,  0.00602307, -0.04591477,  0.04416794,\n",
              "         0.00277691,  0.0861214 , -0.0433574 ,  0.04291598,  0.03403168,\n",
              "        -0.03611547, -0.0012368 , -0.06990376,  0.04342816,  0.00067888,\n",
              "        -0.02622069, -0.00836486, -0.06487729,  0.01786926, -0.00451234,\n",
              "        -0.14011997,  0.05188541, -0.1190051 , -0.05928254,  0.06616351,\n",
              "        -0.03893173,  0.11439636, -0.41910422, -0.10590064,  0.00920938,\n",
              "        -0.05634374,  0.00225484,  0.00622392,  0.06729869, -0.11813046,\n",
              "         0.02609018, -0.12659658,  0.03402869,  0.05733868,  0.00780046,\n",
              "         0.00788761,  0.05200024, -0.03592969,  0.14234933, -0.00050532,\n",
              "         0.05685663, -0.05067255, -0.04757975, -0.04882739, -0.01509907,\n",
              "        -0.26460168, -0.01719018,  0.02710446, -0.11518938,  0.04558586,\n",
              "         0.01119858, -0.00612038,  0.08909725,  0.06920592, -0.03460437,\n",
              "        -0.04030687, -0.02701038,  0.07312858, -0.04463855, -0.04716853,\n",
              "         0.01159769,  0.00058969, -0.03749894, -0.04380123, -0.00404748,\n",
              "        -0.09990501, -0.04605426, -0.06039784, -0.13465112, -0.03917063,\n",
              "         0.05883018, -0.00681456, -0.0010656 , -0.08578716,  0.1522522 ,\n",
              "        -0.0737026 ,  0.05244222, -0.05957975,  0.0600937 , -0.06851818,\n",
              "        -0.02408128,  0.13667135,  0.01100882, -0.05015346, -0.15808864,\n",
              "        -0.05124506,  0.0818245 , -0.0878104 ,  0.00074185, -0.01478006,\n",
              "        -0.04616943,  0.02184368,  0.09971793, -0.05913236,  0.02036935,\n",
              "        -0.06316508, -0.09218919, -0.06335696,  0.02470551, -0.04337867,\n",
              "        -0.04651611, -0.03287821,  0.01856679,  0.0930588 , -0.08567217,\n",
              "        -0.04280565,  0.0458535 , -0.07288383, -0.07545476, -0.03888836,\n",
              "         0.01724328, -0.14742759,  0.0284725 ,  0.07549042,  0.123234  ,\n",
              "        -0.00427257,  0.11671973, -0.02869244,  0.03954781, -0.05967171,\n",
              "         0.0178062 ,  0.08842868,  0.1680997 , -0.08339038,  0.01765503,\n",
              "         0.0215191 ,  0.00597489,  0.1294553 ,  0.01750227,  0.08401275,\n",
              "        -0.01443709, -0.14718732,  0.09027459, -0.01291788,  0.08233427,\n",
              "         0.02622636,  0.04861408, -0.12156966, -0.05018145, -0.06006832,\n",
              "        -0.02179615, -0.08235732,  0.05392993,  0.03603195, -0.0680479 ,\n",
              "        -0.01898463,  0.23160273, -0.09827454, -0.08612779, -0.0872871 ,\n",
              "         0.0153966 , -0.02622591,  0.0290761 ,  0.04783513,  0.00343824,\n",
              "         0.06144572, -0.06903066, -0.00569861,  0.04788749, -0.00709059,\n",
              "        -0.00462361,  0.00162329,  0.13788326,  0.05378735,  0.09449404,\n",
              "        -0.02224284, -0.20482586, -0.02237361,  0.03311033,  0.01013327,\n",
              "         0.00102157,  0.0094011 ,  0.05403632,  0.071053  ,  0.09373933,\n",
              "        -0.12599806,  0.08095978, -0.05111782,  0.00554396,  0.05197378,\n",
              "         0.04673124,  0.16731885, -0.16746087,  0.04134078,  0.00369202,\n",
              "        -0.01303715,  0.08192007,  0.10260179, -0.03612363, -0.04771006,\n",
              "        -0.1167796 , -0.02031164,  0.11551636,  0.15926296, -0.13861388,\n",
              "         0.04334489, -0.05295873, -0.03517263,  0.04881746,  0.18592454,\n",
              "         0.02697713, -0.04463537,  0.17696172, -0.12389262,  0.07139826,\n",
              "        -0.02174208,  0.07223655,  0.10417829,  0.00209176,  0.02541677,\n",
              "         0.06495436,  0.03738799,  0.05276092,  0.02448276, -0.01009833,\n",
              "         0.08234696,  0.11836077,  0.16629446, -0.1231721 , -0.10140122,\n",
              "         0.06482061, -0.07572764, -0.12400118, -0.08512424, -0.010595  ,\n",
              "        -0.0123018 ,  0.12393238, -0.02413586, -0.00974606,  0.05389817,\n",
              "         0.02324396, -0.07926862, -0.03466516, -0.04681061,  0.02191683,\n",
              "         0.22495934, -0.24380258, -0.05319128,  0.02421814,  0.11030754,\n",
              "         0.04888886, -0.3264532 , -0.02686925, -0.03834843,  0.01384027,\n",
              "        -0.02751476, -0.05826189, -0.16039774, -0.11691541,  0.05796935,\n",
              "         0.10032734,  0.12963204,  0.0162252 ,  0.1316502 , -0.06877275,\n",
              "         0.1158494 , -0.01131216,  0.14015044, -0.01059326,  0.01961497,\n",
              "         0.01690337,  0.0043345 , -0.03813679,  0.06683341, -0.0475481 ,\n",
              "        -0.0813938 , -0.04036387,  0.04943958,  0.08423436, -0.05219681,\n",
              "         0.05507591, -0.03687195, -0.04896351, -0.0172025 ,  0.00639679,\n",
              "        -0.05470391,  0.00761363,  0.04741228, -0.00803007, -0.06500432,\n",
              "         0.04386941, -0.06045549,  0.1209643 ,  0.09721132, -0.00953638],\n",
              "       dtype=float32),\n",
              " array([-8.68359767e-03, -1.25998393e-01,  2.91031562e-02, -7.63870915e-03,\n",
              "         1.55065153e-02, -5.55873662e-02, -3.45366411e-02, -2.01854818e-02,\n",
              "        -4.39709388e-02, -9.92244296e-03,  2.27194987e-02,  2.26480812e-02,\n",
              "         2.97641866e-02,  5.13235200e-03, -8.16640109e-02,  4.33459729e-02,\n",
              "         1.09778926e-01, -7.29945898e-02, -2.94759646e-02,  5.12933657e-02,\n",
              "        -6.29223734e-02,  5.51581522e-03, -9.98470411e-02,  5.57795465e-02,\n",
              "         4.62686568e-02, -5.48322611e-02,  7.90059566e-02, -7.98905194e-02,\n",
              "         4.73235324e-02, -1.11664340e-04, -1.29533410e-02,  3.31846476e-02,\n",
              "         8.60484242e-02, -8.23613703e-02,  6.89335763e-02,  6.95408806e-02,\n",
              "         1.52807802e-01, -1.78611398e-01,  1.04161248e-01, -4.69360165e-02,\n",
              "         1.33366417e-02,  1.99145526e-02, -2.11390462e-02, -2.17976924e-02,\n",
              "         7.17701344e-03, -7.84866326e-03, -1.35956407e-01,  3.87715772e-02,\n",
              "        -2.95925047e-02,  3.56956795e-02, -2.29919136e-01, -2.78766118e-02,\n",
              "        -5.46352891e-03,  7.61494190e-02, -8.21086988e-02, -4.40712646e-02,\n",
              "         8.56597126e-02,  1.41501486e-01,  1.90438181e-02, -2.91128960e-02,\n",
              "        -8.11496526e-02,  1.26103088e-01,  1.51320575e-02, -1.00660488e-01,\n",
              "         1.72606739e-03,  4.74928021e-02,  3.85559276e-02,  8.87926668e-02,\n",
              "         8.39347020e-03, -1.21980561e-02, -1.24720871e-01, -8.51631910e-02,\n",
              "         5.46836369e-02,  1.85019337e-03,  4.18157578e-02,  4.50487733e-02,\n",
              "         4.06230986e-02, -4.57409695e-02,  2.35435497e-02, -7.93340504e-02,\n",
              "         9.25608724e-03,  3.35221440e-02,  5.83954975e-02, -1.19978122e-01,\n",
              "        -2.72873640e-02, -5.28128371e-02, -1.68241113e-01, -1.15827784e-01,\n",
              "        -1.60253063e-01, -2.24606879e-03, -1.20791309e-01,  1.64242700e-01,\n",
              "        -3.18761729e-02, -2.76593983e-01,  2.68701231e-03,  3.01708579e-02,\n",
              "         5.79736661e-03,  1.18921492e-02, -4.60966453e-02, -1.45916045e-01,\n",
              "        -1.61478594e-02,  5.87251782e-03, -8.02017748e-02, -6.25862777e-02,\n",
              "        -1.75136197e-02, -3.61297242e-02,  2.02436551e-01,  1.12159610e-01,\n",
              "         1.35169718e-02,  4.76185381e-02,  5.61357252e-02,  7.99438208e-02,\n",
              "        -1.20932860e-02, -1.15924358e-01,  3.66557352e-02, -4.35980260e-02,\n",
              "        -9.95722860e-02, -2.71281879e-02,  1.22932389e-01, -9.93650109e-02,\n",
              "         3.66548705e-03,  1.30813062e-01, -5.69240861e-02,  1.04586504e-01,\n",
              "         5.62859476e-02,  8.67552473e-04,  1.49737090e-01, -5.10158800e-02,\n",
              "         2.93524843e-02,  1.00679681e-01,  1.63309532e-03, -7.54177570e-02,\n",
              "        -3.95305902e-02,  3.49664949e-02, -1.05206713e-01, -2.31338548e-03,\n",
              "        -5.45821190e-02,  1.67317130e-02,  7.66107142e-02,  6.89775422e-02,\n",
              "        -7.42156282e-02, -2.05353480e-02,  1.70994550e-02, -1.03177689e-02,\n",
              "        -2.73686703e-02, -8.71190131e-02, -3.35648358e-02, -1.96012482e-02,\n",
              "        -1.87534448e-02, -3.59322759e-03,  3.43757868e-02,  9.30358022e-02,\n",
              "        -1.52992889e-01,  9.42223072e-02,  5.77977151e-02, -3.09039112e-02,\n",
              "         8.85709375e-02, -5.35532907e-02,  2.01346457e-01,  9.34657305e-02,\n",
              "        -5.55292889e-02, -3.38535309e-02, -7.36540407e-02, -1.31643802e-01,\n",
              "        -6.81563690e-02,  1.34587418e-02, -6.37717173e-02,  3.55311483e-02,\n",
              "         8.13049525e-02, -2.28463747e-02, -5.64718395e-02,  6.08471744e-02,\n",
              "         1.41710073e-01,  4.44226116e-02, -1.75564419e-02,  1.75484002e-01,\n",
              "        -7.05581531e-02,  1.12027109e-01, -4.15240735e-04,  8.62081498e-02,\n",
              "        -9.16353315e-02,  1.69814497e-01, -4.73952442e-02, -1.64579526e-02,\n",
              "        -9.92120728e-02,  8.31564050e-03,  1.52330729e-03,  5.84304184e-02,\n",
              "        -1.93654709e-02,  5.41438423e-02, -8.43610689e-02,  4.34810482e-02,\n",
              "        -3.32723670e-02,  8.16080496e-02, -5.39614670e-02,  6.31704181e-02,\n",
              "         1.08294338e-02, -1.40732676e-01, -1.09313801e-01,  2.08489858e-02,\n",
              "         8.27354044e-02, -1.33997649e-02,  2.36012638e-02, -5.82205355e-02,\n",
              "         3.18081677e-02, -2.10785791e-01,  2.81077530e-02,  7.20504895e-02,\n",
              "        -2.21851729e-02, -5.52675538e-02,  2.13497192e-01, -9.76617634e-02,\n",
              "        -1.41931716e-02, -1.88740976e-02,  5.28526828e-02, -1.88814532e-02,\n",
              "        -4.59697358e-02,  1.65673465e-01, -2.48934682e-02,  5.32487445e-02,\n",
              "         2.23600827e-02, -5.36497496e-02,  8.14811289e-02,  1.57228075e-02,\n",
              "        -2.43866712e-01, -1.28722250e-01, -2.07337551e-02,  4.57691103e-02,\n",
              "        -2.70588547e-02, -3.22771966e-02, -8.25589225e-02,  6.41157031e-02,\n",
              "         4.61558178e-02,  7.50003085e-02,  4.56108451e-02, -3.23478878e-02,\n",
              "         2.99071353e-02,  2.75264736e-02, -7.70742819e-02, -2.88738813e-02,\n",
              "         2.39029862e-02,  1.89778015e-01, -4.97756563e-02,  3.68969962e-02,\n",
              "        -1.40942289e-02,  4.84564118e-02,  1.06670737e-01, -1.59087390e-01,\n",
              "        -1.06444836e-01,  5.39931357e-02,  1.75163075e-01, -1.75176691e-02,\n",
              "         8.99385735e-02,  3.24288756e-02,  1.39753595e-01, -1.41680613e-03,\n",
              "        -4.85128276e-02, -4.21604142e-02,  1.87068284e-02, -1.92889139e-01,\n",
              "        -7.54759386e-02,  7.28291571e-02,  2.15158379e-03, -1.17951944e-01,\n",
              "         1.01354346e-02, -3.17686126e-02,  8.76927003e-02,  8.56513977e-02,\n",
              "         8.44825655e-02,  9.02590975e-02,  2.12358665e-02, -8.15159678e-02,\n",
              "         1.23571277e-01, -4.18854877e-02,  1.56785309e-01,  1.94161683e-02,\n",
              "        -5.50720505e-02,  7.06775766e-03,  8.19836259e-02,  1.96676597e-01,\n",
              "        -5.85140809e-02,  3.98695096e-02,  1.04277186e-01,  8.44438560e-03,\n",
              "        -4.56798449e-03,  1.75201952e-01, -6.47393018e-02, -2.82024294e-02,\n",
              "        -1.97891116e-01,  9.77291763e-02, -5.12566082e-02,  9.95184332e-02,\n",
              "         4.77732196e-02, -5.71182631e-02,  2.36417092e-02, -7.34644383e-02,\n",
              "         4.39367816e-02, -3.29164043e-02, -5.00851087e-02, -5.64888790e-02],\n",
              "       dtype=float32)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_fasttext_embeddings(\"Как дела ?\", 'cc.ru.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A9GXy6n0AtsZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-2.11662680e-01,  1.05942465e-01, -9.13959071e-02,  3.88246588e-02,\n",
              "        4.02548164e-02, -9.39927995e-02,  1.00112945e-01,  1.49683088e-01,\n",
              "        8.21771380e-03, -2.24750638e-01, -3.08279507e-02, -1.32319078e-01,\n",
              "       -4.91843149e-02,  2.67478794e-01,  4.93385792e-02,  4.20542397e-02,\n",
              "       -2.13875383e-01,  3.60601954e-02,  1.09178804e-01, -1.12872906e-01,\n",
              "       -4.41864803e-02, -7.53838615e-03, -2.10865125e-01,  1.78922825e-02,\n",
              "        9.60436314e-02,  2.21718960e-02,  4.33516242e-02, -3.18819851e-01,\n",
              "        7.56375492e-02, -2.98691168e-02,  6.72985017e-02,  6.21551834e-02,\n",
              "       -5.56395911e-02,  1.18431300e-01, -3.26865703e-01, -1.15149096e-02,\n",
              "       -7.18370313e-04,  2.31557377e-02, -2.00062916e-01,  2.31627543e-02,\n",
              "        9.22629088e-02, -1.53513283e-01,  2.75566250e-01, -1.05859660e-01,\n",
              "       -7.10882246e-02, -4.85530645e-02, -1.68746352e+00, -2.08344217e-02,\n",
              "       -2.86590874e-01, -2.08238006e-01, -3.52022871e-02,  3.82979847e-02,\n",
              "        3.51018786e-01,  6.10413700e-02, -4.96922247e-02,  1.30560964e-01,\n",
              "       -1.27682552e-01,  5.81380844e-01, -3.79880853e-02, -1.89852208e-01,\n",
              "        1.19115874e-01,  1.34065464e-01,  1.14678569e-01,  7.88414627e-02,\n",
              "       -3.77306305e-02,  2.84280419e-01,  5.34263514e-02,  1.69602066e-01,\n",
              "       -4.69032042e-02,  4.52703565e-01, -3.01490091e-02, -1.84354335e-01,\n",
              "        2.58332849e-01,  2.34587952e-01, -1.44584477e-01, -2.33659923e-01,\n",
              "        1.01993769e-01, -4.57560737e-03, -7.94322938e-02, -6.12117723e-03,\n",
              "        9.46174487e-02,  1.94520965e-01,  9.46434736e-02,  1.34654567e-01,\n",
              "        1.96648806e-01,  3.06723475e-01, -2.56414473e-01,  1.05002157e-01,\n",
              "        7.73894936e-02,  5.34097433e-01,  3.90626863e-02, -6.91561252e-02,\n",
              "       -5.55718644e-03,  4.53403026e-01,  3.27487439e-01, -3.93325359e-01,\n",
              "        2.04847172e-01, -8.49455222e-02,  1.01469219e-01,  2.69439071e-01,\n",
              "       -2.98656547e-03, -1.87235519e-01, -4.55103926e-02, -1.94823548e-01,\n",
              "       -1.14980958e-01,  1.06789410e-01,  7.06061348e-02, -1.76864251e-01,\n",
              "        4.11780924e-02, -2.82686901e+00,  6.34192005e-02,  2.65259892e-02,\n",
              "       -4.15553921e-04,  2.13298630e-02, -5.80092221e-02,  6.11189842e-01,\n",
              "        2.09888369e-01,  1.01582579e-01, -5.61551489e-02, -2.57129312e-01,\n",
              "       -5.53391688e-02,  5.19807935e-01,  1.27847567e-01, -6.54023066e-02,\n",
              "        3.77065420e-01,  2.05543250e-01, -1.47560388e-01, -2.33452529e-01,\n",
              "        2.55940147e-02, -1.60110053e-02,  3.35487649e-02,  3.79267931e-01,\n",
              "        6.72893301e-02, -1.25285730e-01, -3.81828249e-02,  1.57168005e-02,\n",
              "        1.32781163e-01, -9.14546400e-02, -8.35815519e-02, -1.16127633e-01,\n",
              "       -4.38201651e-02,  1.55134350e-01, -3.46085501e+00,  1.01487957e-01,\n",
              "        2.19402194e-01, -4.20311421e-01, -3.77285093e-01, -1.13003999e-01,\n",
              "       -2.70072203e-02,  2.73156073e-02, -8.39995444e-02,  2.93842480e-02,\n",
              "       -2.29701713e-01, -7.33788684e-02, -2.64250696e-01, -8.68334994e-02,\n",
              "       -3.01051617e-01, -3.65628600e-02,  1.39480531e-01,  1.87243056e-02,\n",
              "       -8.89660195e-02, -6.00134507e-02, -8.54065567e-02, -1.72918901e-01,\n",
              "       -1.11305319e-01, -2.97211260e-01,  2.32713938e-01,  5.13934553e-01,\n",
              "        1.71297863e-01,  9.73494276e-02, -4.03377831e-01, -4.45416570e-02,\n",
              "        1.33691207e-01,  4.10749078e-01, -1.22823916e-01, -1.67331964e-01,\n",
              "        2.72889882e-01,  1.08793683e-01,  2.31730700e-01,  1.43450171e-01,\n",
              "       -5.54520227e-02,  4.70053285e-01, -1.37853667e-01, -7.44416639e-02,\n",
              "        1.01151347e-01,  7.06785172e-02,  2.77488500e-01, -2.33552396e-01,\n",
              "        2.04996485e-03,  2.09919319e-01, -1.31115422e-01,  2.30132882e-02,\n",
              "        1.39656603e-01,  1.57113209e-01,  1.55066550e-01, -8.43582004e-02,\n",
              "        1.64014593e-01, -2.06794813e-01,  5.40081918e-01,  1.15388930e-01,\n",
              "        9.90730971e-02,  7.30857486e-03, -1.49338841e-01, -2.01173145e-02,\n",
              "        8.01535845e-02,  3.90477014e+00,  3.61126028e-02, -2.63954759e-01,\n",
              "        1.94133520e-01,  3.37214805e-02, -7.35591725e-03,  2.63732344e-01,\n",
              "        2.23556384e-01, -7.92756602e-02,  5.37501983e-02, -5.56623153e-02,\n",
              "        3.69861633e-01,  2.04190060e-01, -1.57605305e-01, -3.35478671e-02,\n",
              "        4.40707147e-01,  1.21474154e-01,  1.78275868e-01,  1.99390929e-02,\n",
              "       -1.71062611e-02, -3.58503498e-02,  2.99769640e-01, -2.20558466e-03,\n",
              "       -1.72277898e-01, -7.77365565e-01, -1.33337453e-01, -2.68573999e-01,\n",
              "       -2.26193637e-01,  2.96581864e-01, -2.63789445e-01,  6.16304502e-02,\n",
              "        5.33584431e-02, -1.54602379e-01,  1.31447494e-01,  3.78182270e-02,\n",
              "        2.66239177e-02,  2.07950562e-01,  2.60466814e-01,  2.74039894e-01,\n",
              "       -1.88735306e-01,  2.37792805e-01,  2.48336121e-01,  1.69802174e-01,\n",
              "        2.48932481e-01, -1.26001090e-01, -2.97025517e-02, -2.11292863e-01,\n",
              "       -1.05619371e-01,  5.23753241e-02, -7.93642849e-02, -2.38387525e-01,\n",
              "       -3.42216715e-02,  1.51452169e-01, -4.93263341e-02,  7.63784274e-02,\n",
              "       -2.79503793e-01, -3.49426568e-01,  1.81071147e-01,  2.55494714e-02,\n",
              "       -6.28111213e-02,  4.06590514e-02,  1.64440587e-01, -1.12744845e-01,\n",
              "        1.40460238e-01,  7.57390261e-02,  1.21466190e-01,  1.64975792e-01,\n",
              "       -2.13885233e-02, -4.88351536e+00,  2.50569135e-01,  6.09156750e-02,\n",
              "        1.90974712e-01,  2.68353492e-01,  1.07373171e-01,  6.37294129e-02,\n",
              "        6.46122396e-02, -5.49067883e-03, -1.41268894e-01, -6.61121085e-02,\n",
              "        1.92437813e-01, -3.12428147e-01,  2.36863449e-01, -4.59639013e-01,\n",
              "        1.90179735e-01,  3.96082699e-02, -3.85738462e-02, -1.55597493e-01,\n",
              "        1.02157274e-03,  1.46671375e-02,  4.22622174e-01, -2.72641748e-01,\n",
              "       -2.55296398e-02,  1.23632759e-01, -2.89844066e-01, -2.28273198e-02,\n",
              "        9.61876139e-02,  3.48115951e-01, -3.49885792e-01, -1.11131914e-01,\n",
              "        5.41878641e-02, -3.26520726e-02,  3.46773416e-02,  1.51396859e-02,\n",
              "       -2.17213631e+00, -5.51290438e-02,  2.42680952e-01, -2.33835280e-01,\n",
              "        2.02525944e-01, -4.20552539e-03, -7.09657138e-03,  9.74091142e-03,\n",
              "       -9.41288993e-02,  1.17686704e-01,  1.17016502e-01,  2.38187447e-01,\n",
              "       -1.73871741e-01,  6.28375262e-02, -5.41795278e-03, -3.48239005e-01,\n",
              "       -2.39692386e-02,  3.70570943e-02, -2.29422450e-01, -1.45462649e-02,\n",
              "       -6.88774837e-03,  3.13318111e-02,  9.98490155e-02,  4.07977812e-02,\n",
              "       -2.20361471e-01,  2.94936478e-01, -1.74101010e-01,  4.01722789e-02,\n",
              "       -3.39701265e-01,  9.14412737e-02, -2.90801495e-01, -7.05151930e-02,\n",
              "        8.14984664e-02,  2.85487711e-01,  5.19266725e-02, -5.61462268e-02,\n",
              "        2.67468363e-01,  7.26633593e-02,  4.15324420e-01,  2.81840339e-02,\n",
              "        7.69891366e-02,  2.48647466e-01,  2.70918965e-01,  3.61479133e-01,\n",
              "        2.23909333e-01, -5.32984398e-02, -4.49500233e-02, -8.71208776e-03,\n",
              "        1.10993218e-02,  3.46965231e-02, -4.42017168e-02,  9.03534219e-02,\n",
              "        1.00263524e+00, -1.80866435e-01,  2.35450044e-01, -1.19309917e-01,\n",
              "        2.35032424e-01,  7.02851564e-02,  1.90783590e-01,  4.76619005e-02,\n",
              "        2.96001434e-01,  3.17602962e-01,  2.38759875e-01,  2.66479135e-01,\n",
              "       -1.66042849e-01, -2.48572648e-01, -6.84502274e-02, -2.15092480e-01,\n",
              "        1.60972297e-01, -4.27914895e-02, -2.31397115e-02, -7.71570718e-03,\n",
              "        1.08539037e-01, -5.60365140e-01, -1.33873835e-01,  3.71228218e-01,\n",
              "       -6.48127869e-02,  2.08693985e-02,  3.39900047e-01, -1.71593174e-01,\n",
              "        6.49947450e-02, -8.80560949e-02,  7.13312775e-02,  3.96421969e-01,\n",
              "       -1.29900515e-01,  8.53603240e-03,  5.92013709e-02,  3.94565538e-02,\n",
              "       -1.23425618e-01,  2.63933688e-01, -6.12988584e-02,  4.65731882e-02,\n",
              "       -4.59879152e-02, -8.07833374e-02, -2.56460253e-02,  6.09575361e-02,\n",
              "       -4.94208261e-02, -6.22965157e-01,  1.53691575e-01, -1.91392869e-01,\n",
              "       -2.46471703e-01, -2.62401909e-01, -2.37690568e-01,  2.00763389e-01,\n",
              "       -7.55766556e-02,  9.15503874e-02, -2.08781198e-01,  4.83471826e-02,\n",
              "       -5.19791469e-02,  1.12379000e-01,  1.29053205e-01,  1.40069932e-01,\n",
              "        9.56277475e-02,  1.53078228e-01,  4.54097211e-01,  7.59587288e-02,\n",
              "        2.26181865e-01,  2.65908837e-01,  1.13479204e-01,  1.61447361e-01,\n",
              "        3.88076901e-02,  2.20295250e-01,  1.77248876e-05,  1.23829760e-01,\n",
              "        1.53700843e-01,  5.56616299e-02, -1.66952307e-03, -2.38280833e-01,\n",
              "       -3.90435308e-01, -7.33803064e-02,  3.54279093e-02, -1.42475098e-01,\n",
              "        1.80870473e-01, -5.80695510e-01, -4.33819354e-01, -1.42682746e-01,\n",
              "       -1.54340163e-01,  1.01979794e-02, -1.24519870e-01,  3.38689893e-01,\n",
              "        2.14180008e-01, -5.72068915e-02, -6.18521310e-02,  3.76705587e-01,\n",
              "        1.90432310e-01,  2.36057416e-01, -5.08653037e-02, -6.73758313e-02,\n",
              "       -1.32099390e-01,  1.62970856e-01, -2.57195886e-02, -4.08595473e-01,\n",
              "        2.08057538e-01, -4.34678560e-03, -1.42933354e-01,  2.06136197e-01,\n",
              "        1.98060766e-01, -1.70236394e-01,  1.07128978e-01,  2.14753419e-01,\n",
              "        5.98334931e-02,  4.47250949e-03, -9.39934015e-01,  2.90047884e-01,\n",
              "        5.09479828e-02,  3.27643864e-02,  8.48720744e-02,  1.89528048e-01,\n",
              "       -1.60256654e-01,  3.59148026e-01,  8.68574679e-02, -8.54192600e-02,\n",
              "       -2.40679719e-02,  7.62967840e-02, -8.12741593e-02,  7.62589872e-02,\n",
              "       -1.33331686e-01,  2.24118337e-01,  2.59195626e-01, -2.47305334e-01,\n",
              "       -1.56319663e-02,  1.27919108e-01,  2.99494024e-02,  1.19288675e-01,\n",
              "        8.47486127e-03, -5.81705756e-02, -8.81617982e-03, -1.06872119e-01,\n",
              "        2.78600752e-02,  4.19415295e-01,  7.66765550e-02,  1.25985935e-01,\n",
              "        7.43721332e-03, -4.14728969e-01, -1.03390865e-01,  3.59804034e-02,\n",
              "        8.16372335e-02, -1.63799077e-01,  9.69006866e-02,  1.64166823e-01,\n",
              "        6.61375076e-02, -7.35012665e-02, -1.27952263e-01,  1.00160748e-01,\n",
              "        2.28844494e-01, -2.77366251e-01,  3.23374867e-01,  3.48085821e-01,\n",
              "       -9.24673975e-02,  3.69480834e-03,  1.05456702e-01, -1.40860394e-01,\n",
              "       -1.91846862e-01,  5.99676445e-02, -1.71153814e-01,  2.43443809e-03,\n",
              "        1.52787805e-01,  5.17113954e-02,  9.69089866e-02, -9.84630212e-02,\n",
              "       -1.08941877e-02, -1.51492953e-01,  1.56404257e-01, -7.30114207e-02,\n",
              "        6.90541863e-02,  1.80387095e-01, -3.08654249e-01, -2.12041318e-01,\n",
              "        7.61403069e-02, -4.36910018e-02,  8.15464780e-02, -5.47400750e-02,\n",
              "        2.21533313e-01, -2.30440140e-01, -2.90511400e-01,  5.04497103e-02,\n",
              "       -1.45075336e-01,  7.53698945e-02,  4.83186878e-02,  1.50130168e-02,\n",
              "        2.32929960e-01, -3.07962865e-01, -3.59427780e-02,  4.39090766e-02,\n",
              "       -1.86476946e-01,  2.56298751e-01,  4.04275991e-02,  7.92343840e-02,\n",
              "        3.38139921e-01,  4.13334556e-02, -2.30773702e-01,  7.75818527e-02,\n",
              "       -1.59845501e-01, -1.92063823e-02,  4.34405297e-01, -8.95605609e-02,\n",
              "        1.13600411e-01,  5.55197103e-03,  1.28525779e-01,  6.62090927e-02,\n",
              "       -1.80338442e-01,  1.71413377e-01, -1.66321620e-01,  1.88095063e-01,\n",
              "        6.57247603e-02,  1.08678892e-01,  2.07960710e-01,  4.93018478e-02,\n",
              "        3.86043638e-01,  2.06773892e-01, -1.71222478e-01, -7.43965358e-02,\n",
              "       -2.75445402e-01,  2.88852602e-01, -2.74419814e-01, -1.53033137e-01,\n",
              "        7.62062296e-02,  2.07065210e-01,  1.96281329e-01, -4.65493686e-02,\n",
              "        2.78061461e+00,  4.71811622e-01,  2.30108395e-01, -2.89380830e-03,\n",
              "        6.84348047e-02,  5.54337762e-02,  9.21597555e-02, -8.44008848e-02,\n",
              "       -2.20399678e-01,  1.51781082e-01, -2.08152309e-02,  1.10543929e-01,\n",
              "        1.51451528e-01,  1.26259461e-01,  1.95358425e-01,  1.07994899e-02,\n",
              "       -2.90471822e-01, -9.32170376e-02, -2.49948919e-01, -7.55421305e-03,\n",
              "       -2.11669698e-01, -2.03702047e-01, -7.71319270e-02, -1.85269207e-01,\n",
              "       -6.55376688e-02,  1.48082614e-01, -2.36094762e-02, -8.51288787e-04,\n",
              "       -4.96247923e-03, -6.26006797e-02, -7.00665042e-02, -1.86699316e-01,\n",
              "       -6.19056262e-02, -1.39193743e-01, -1.11339398e-01,  2.01047093e-01,\n",
              "       -6.95800409e-02, -3.32334757e-01, -4.01268005e-02,  2.52607197e-01,\n",
              "       -5.83129190e-02, -8.06472749e-02,  2.15113565e-01,  2.39897892e-01,\n",
              "        3.11085999e-01,  3.46223235e-01,  2.21731346e-02,  6.77537248e-02,\n",
              "        3.21463645e-01,  1.06593808e-02, -1.82196498e-01, -4.75080870e-02,\n",
              "       -2.61288911e-01, -3.89953963e-02,  2.32573934e-02, -4.22740459e-01,\n",
              "        3.54634434e-01, -1.14454634e-01, -1.42393606e-02, -7.72826597e-02,\n",
              "        2.11060658e-01, -1.55887678e-01,  2.42631137e-01, -2.49408439e-01,\n",
              "       -2.11978942e-01,  2.42040306e-01, -3.93383503e-02, -4.38343510e-02,\n",
              "        2.57156100e-02,  1.19116902e-01, -1.18223041e-01, -6.23358339e-02,\n",
              "       -1.05787069e-01, -8.22993144e-02, -3.72269191e-02, -1.53226569e-01,\n",
              "       -3.93890357e-03, -3.37639488e-02, -3.52419525e-01, -3.62624955e+00,\n",
              "       -1.49549702e-02, -1.75299138e-01,  5.93118556e-02,  1.28056193e-02,\n",
              "        1.52553052e-01,  2.75175959e-01,  3.77642550e-02, -1.15504034e-01,\n",
              "       -1.27516851e-01, -4.09463868e-02,  1.08605921e-01,  7.33704418e-02,\n",
              "        1.04359403e-01, -5.44167217e-03, -5.52731827e-02, -1.37947332e-02,\n",
              "       -3.86037469e-01, -1.66309029e-01, -2.81180441e-01, -1.20908357e-01,\n",
              "       -1.49256676e-01, -1.34656280e-01, -9.23029929e-02, -2.12303713e-01,\n",
              "        2.33882979e-01,  1.03044242e-01, -1.34064764e-01,  8.24513361e-02,\n",
              "        4.50334065e-02,  4.97259106e-03,  2.96996295e-01, -1.12883337e-01,\n",
              "        1.60417169e-01,  6.43462315e-02, -1.14264108e-01,  1.53263947e-02,\n",
              "       -3.58891450e-02,  1.34144902e-01,  2.41141737e-01,  6.18650429e-02,\n",
              "        3.43545228e-01,  1.78187191e-01,  7.21086413e-02, -2.40553454e-01,\n",
              "       -2.19289467e-01,  2.44037777e-01, -1.99674498e-02,  7.16018453e-02,\n",
              "       -8.08526576e-02, -1.04822097e-02,  2.58522302e-01, -3.23196165e-02,\n",
              "        1.47979215e-01,  2.22099721e-01,  3.93889099e-02, -1.97890118e-01,\n",
              "       -9.93923843e-02,  1.46562770e-01,  3.38068716e-02,  1.68305993e-01,\n",
              "        1.07447319e-02,  2.70427078e-01, -1.68796733e-01,  3.21165770e-01,\n",
              "       -3.26683134e-01,  4.51377295e-02, -3.03158104e-01,  8.28889534e-02,\n",
              "        5.30952588e-02,  2.65092880e-01, -1.97662234e-01,  2.92580009e-01,\n",
              "       -2.09942564e-01, -2.76796855e-02,  1.40449464e-01,  3.62599254e-01,\n",
              "        1.30950227e-01, -2.89904296e-01,  2.53627390e-01,  7.14154094e-02,\n",
              "       -1.96372613e-01, -1.73760846e-01,  1.90065086e-01,  7.30339363e-02,\n",
              "       -9.42437744e+00, -1.04959704e-01, -1.88815907e-01,  8.43851715e-02,\n",
              "        2.65715986e-01,  1.66023880e-01,  2.14272380e-01, -3.50797474e-02,\n",
              "        9.05929226e-03,  8.43065456e-02, -1.53971165e-01, -1.90374598e-01,\n",
              "       -1.86201390e-02, -1.56572565e-01,  5.25218695e-02, -7.12941438e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_bert_embeddings(\n",
        "    text: str,\n",
        "    model_name: str = 'bert-base-uncased',\n",
        "    pool_method: str = 'cls'\n",
        ") -> np.ndarray:\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "    model.eval()\n",
        "    inputs = tokenizer(normalize_pretokenize_text(text), return_tensors= 'pt', truncation= True, padding= True, max_length= 512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    last_hidden_state = outputs.last_hidden_state\n",
        "    if pool_method == 'cls':\n",
        "        sentence_embedding = last_hidden_state[0, 0, :]\n",
        "    return sentence_embedding.cpu().numpy()\n",
        "\n",
        "get_bert_embeddings(\"How many tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_KoKolrD49R"
      },
      "source": [
        "## Задание 6 (1.5 балла)\n",
        "Реализовать обучение так, чтобы можно было поверх эмбеддингов, реализованных в предыдущих заданиях, обучить какую-то модель (вероятно неглубокую, например, CatBoost) на задаче классификации текстов ([IMDB](https://huggingface.co/datasets/stanfordnlp/imdb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zsc98L8JE8G-"
      },
      "outputs": [],
      "source": [
        "def vectorize_dataset(\n",
        "    dataset_name: str = \"stanfordnlp/imdb\",\n",
        "    vectorizer_type: str = \"bow\",\n",
        "    split: str = \"train\",\n",
        "    sample_size: int = 2500,\n",
        "    vocab: List[str] = None,\n",
        "    vocab_index: Dict[str, int] = None\n",
        ") -> Tuple[Any, List, List]:\n",
        "\n",
        "    dataset = datasets.load_dataset(dataset_name, split=split)\n",
        "\n",
        "    if sample_size:\n",
        "        dataset = dataset.shuffle(seed=42)\n",
        "        dataset = dataset.select(range(min(sample_size, len(dataset))))\n",
        "\n",
        "    texts = [item['text'] for item in dataset if 'text' in item and item['text'].strip()]\n",
        "    labels = [item['label'] for item in dataset if 'label' in item]\n",
        "\n",
        "    def build_vocab(texts: List[str]) -> Tuple[List[str], Dict[str, int]]:\n",
        "        all_words = []\n",
        "        for text in texts:\n",
        "            words = normalize_pretokenize_text(text)\n",
        "            all_words.extend(words)\n",
        "        vocab = sorted(set(all_words))\n",
        "        vocab_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "        return vocab, vocab_index\n",
        "    \n",
        "    if vocab is None or vocab_index is None:\n",
        "        print(\"Словарь не передан, строим новый на основе текущих данных...\")    \n",
        "        vocab, vocab_index = build_vocab(texts)\n",
        "    else:\n",
        "        print(\"Используем существующий словарь...\")\n",
        "\n",
        "    vectorized_data = []\n",
        "    for text in texts:\n",
        "        if vectorizer_type == \"one_hot\":\n",
        "            vectorized_data.append(one_hot_vectorization(text, vocab, vocab_index))\n",
        "        elif vectorizer_type == \"bow\":\n",
        "            bow_dict = bag_of_words_vectorization(text)\n",
        "            vector = [bow_dict.get(word, 0) for word in vocab]\n",
        "            vectorized_data.append(vector)\n",
        "        elif vectorizer_type == \"tfidf\":\n",
        "            vectorized_data.append(tf_idf_vectorization(text, texts))\n",
        "        elif vectorizer_type == \"ppmi\":\n",
        "            vectorized_data.append(ppmi_vectorization(text, texts, vocab, vocab_index))\n",
        "        elif vectorizer_type == \"fasttext\":\n",
        "            embeddings = get_fasttext_embeddings(text)\n",
        "            if embeddings:\n",
        "                avg_embedding = np.mean(embeddings, axis=0)\n",
        "                vectorized_data.append(avg_embedding.tolist())\n",
        "            else:\n",
        "                vectorized_data.append([0] * 300)\n",
        "        elif vectorizer_type == \"bert\":\n",
        "            embedding = get_bert_embeddings(text)\n",
        "            vectorized_data.append(embedding.tolist())\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown vectorizer type: {vectorizer_type}\")\n",
        "    return vocab, vocab_index, vectorized_data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DRRw01XiBg6H"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "\n",
        "def train(\n",
        "    embeddings_method=\"bow\",\n",
        "    test_size=0.2,\n",
        "    val_size=0.2,\n",
        "    cv_folds=5\n",
        "):\n",
        "    print(f\"=== Метод {embeddings_method} ===\")\n",
        "    vocab, vocab_index, X, y = vectorize_dataset(\"stanfordnlp/imdb\", embeddings_method, \"train\")\n",
        "\n",
        "    model_for_cv = CatBoostClassifier(iterations=100,\n",
        "                                      verbose=0,\n",
        "                                      random_state=42,\n",
        "                                      task_type='GPU')\n",
        "\n",
        "\n",
        "    kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    scores = cross_val_score(model_for_cv, X, y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    print(\"\\n--- Результаты кросс-валидации ---\")\n",
        "    print(f\"Точность на каждом фолде: {np.round(scores, 4)}\")\n",
        "    print(f\"Средняя точность (CV Accuracy): {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size= val_size, stratify= y)\n",
        "    _, _, X_test, y_test = vectorize_dataset(\"stanfordnlp/imdb\", embeddings_method, \"test\", vocab= vocab, vocab_index= vocab_index)\n",
        "\n",
        "    model = CatBoostClassifier(iterations= 100,\n",
        "                               verbose= 0,\n",
        "                               random_state= 42,\n",
        "                               task_type= 'GPU')\n",
        "    model.fit(X_train, \n",
        "              y_train, \n",
        "              eval_set= (X_val, y_val))\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average= 'weighted')\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    \n",
        "    print(\"\\n--- Результаты ---\")\n",
        "    print(f\"Точность (Accuracy) на тестовой выборке: {accuracy:.4f}\")\n",
        "    print(f\"F1-мера (Weighted) на тестовой выборке: {f1:.4f}\")\n",
        "    print(\"\\nПолный отчет по классификации:\")\n",
        "    print(report)\n",
        "    print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "naMqAkjqFHAe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Метод bow ===\n",
            "Словарь не передан, строим новый на основе текущих данных...\n",
            "\n",
            "--- Результаты кросс-валидации ---\n",
            "Точность на каждом фолде: [0.782 0.836 0.792 0.778 0.812]\n",
            "Средняя точность (CV Accuracy): 0.8000 (+/- 0.0215)\n",
            "==================================================\n",
            "Используем существующий словарь...\n",
            "\n",
            "--- Результаты ---\n",
            "Точность (Accuracy) на тестовой выборке: 0.8196\n",
            "F1-мера (Weighted) на тестовой выборке: 0.8191\n",
            "\n",
            "Полный отчет по классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81      1243\n",
            "           1       0.79      0.87      0.83      1257\n",
            "\n",
            "    accuracy                           0.82      2500\n",
            "   macro avg       0.82      0.82      0.82      2500\n",
            "weighted avg       0.82      0.82      0.82      2500\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "train(embeddings_method='bow')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "math",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
